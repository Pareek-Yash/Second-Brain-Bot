{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from chat_history import insert_data, get_last_conversation, get_prev_queries\n",
    "from vector_retrieval import create_context\n",
    "import mysql.connector\n",
    "import weaviate\n",
    "import tiktoken\n",
    "import requests\n",
    "import openai\n",
    "import json\n",
    "\n",
    "\n",
    "openai.api_key = '<<Your API Key>>'\n",
    "auth_config = weaviate.auth.AuthApiKey(api_key=\"<<Your API Key>>\")\n",
    "client = weaviate.Client(\n",
    "    url = \"Replace with your endpoint\",  \n",
    "    auth_client_secret=auth_config,\n",
    "    additional_headers = {\n",
    "        \"X-Cohere-Api-Key\" : \"<<Your API Key>>\" # Replace with your API key\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "openai.api_key = '<<Your API Key>>'\n",
    "co = cohere.Client('<<Your API Key>>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(\n",
    "    prompt,\n",
    "    debug=False,\n",
    "    max_tokens=100,\n",
    "    stop_sequence=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Answer a question based on the most similar context from the dataframe texts\n",
    "    \"\"\"\n",
    "    try:\n",
    "        #print(instruction.format(context, question))\n",
    "        response = openai.Completion.create(\n",
    "            model = \"text-davinci-003\",\n",
    "            prompt=prompt,\n",
    "            temperature=0.5,\n",
    "            max_tokens=max_tokens,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=None,\n",
    "            stream=True,\n",
    "            best_of = \n",
    "        )\n",
    "\n",
    "        generated_text = \"\"\n",
    "        for line in response:\n",
    "            generated_text += line.choices[0].text  # extract the text from the StreamingText object\n",
    "        \n",
    "        return generated_text.split(\"###\")[0].strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_tokens(prompt):\n",
    "    encoding = tiktoken.encoding_for_model(\"text-davinci-003\")\n",
    "    num_tokens = len(encoding.encode(prompt))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(uuid, vec_class, question, debug=False):\n",
    "    # Initialize Database\n",
    "    mydb = mysql.connector.connect(\n",
    "        host=\"<<Database endpoint>>\",\n",
    "        user=\"\",\n",
    "        password=\"\",\n",
    "        database=\"\"\n",
    "    )\n",
    "\n",
    "    # Retrieve last conversation for the vec_class\n",
    "    last_conversation = get_last_conversation(mydb, uuid, vec_class)\n",
    "    prev_queries = get_prev_queries(mydb, uuid, vec_class)\n",
    "\n",
    "    # Get Context for answering question\n",
    "    context = create_context(\n",
    "        question,\n",
    "        prev_queries,\n",
    "        vec_class  \n",
    "    )\n",
    "\n",
    "    # Print context while debugging\n",
    "\n",
    "        \n",
    "    \n",
    "    # If there was a previous conversation, include it in the prompt\n",
    "    if last_conversation is not None:\n",
    "        prompt = f'''You are an AI language model that provides answers based on the given context and previous conversations. Your task is to answer the following question using the provided Knowledge Base and previous conversations all delimited by three backticks:\n",
    "            If any relevant link is available in the Knowledge Base make sure to include them in the answer.\n",
    "            Do not attempt to make up any answer yourself.\n",
    "            \\n\\n \n",
    "            ```Knowledge Base: \\n{context}```\\n\\n---\\n\\n\n",
    "            ```Previous Conversations: {last_conversation}```\\n\n",
    "            Question: {question}\\n\n",
    "            Answer:\n",
    "        '''\n",
    "    else:\n",
    "        prompt = f'''You are an AI language model that provides answers based on the given context. Your task is to answer the following question using the provided Knowledge Base delimited by three backticks: \n",
    "            If no question is asked and the user simply greets you. You greet them back politely.\n",
    "            If relevant link is available in the Knowledge Base include them in the answer.\n",
    "            Do not attempt to make up any answer yourself.\n",
    "            \\n\\n ```Knowledge Base: \\n{context}```\\n\\n---\\n\\n\n",
    "            Question: {question}\\n\n",
    "            Answer:\n",
    "        '''\n",
    "    \n",
    "    num_tokens = calculate_tokens(prompt)\n",
    "\n",
    "    if debug:\n",
    "        print(\"Last 3 Queries: \", prev_queries)\n",
    "        print(\"Last 3 Conversation: \", last_conversation)\n",
    "        print(context)\n",
    "        print(\"Num Tokens: \", num_tokens)\n",
    "    \n",
    "    # Generate response from OpenAI API\n",
    "    response = generate_response(prompt)\n",
    "    \n",
    "    # Insert conversation into the database\n",
    "    # uuid = str(uuid.uuid4())\n",
    "    # chat_conv = f\"{context}\\n\\n---\\n\\nQuestion: {question}\\nAnswer: {response}\"\n",
    "    chat_conv = f\"Question: {question} Answer: {response}\"\n",
    "    insert_data(mydb, vec_class, uuid, question, chat_conv)\n",
    "\n",
    "    mydb.close()\n",
    "    \n",
    "    # Return response to the user\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =''\n",
    "uuid=''\n",
    "vec_class = ''\n",
    "lang_code = detect_lang(query)\n",
    "print(lang_code)\n",
    "if lang_code == 'EN':\n",
    "    result = chatbot(uuid, vec_class, query, debug = True)\n",
    "else:\n",
    "    trans_query = user_lang(query, 'EN')\n",
    "    answer = chatbot(uuid, vec_class, trans_query, debug = True)\n",
    "    result = user_lang(answer, lang_code)\n",
    "\n",
    "print(result)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intentrec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
