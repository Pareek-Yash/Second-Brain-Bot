{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import mysql.connector\n",
    "import weaviate\n",
    "import tiktoken\n",
    "import requests\n",
    "import openai\n",
    "import json\n",
    "\n",
    "\n",
    "openai.api_key = '<<Your API Key>>'\n",
    "auth_config = weaviate.auth.AuthApiKey(api_key=\"<<Your API Key>>\")\n",
    "client = weaviate.Client(\n",
    "    url = \"Replace with your endpoint\",  \n",
    "    auth_client_secret=auth_config,\n",
    "    additional_headers = {\n",
    "        \"X-Cohere-Api-Key\" : \"<<Your API Key>>\" # Replace with your API key\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "openai.api_key = '<<Your API Key>>'\n",
    "co = cohere.Client('<<Your API Key>>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data(mydb, vec_class, uuid, question, chat_conv):\n",
    "    # Check if UUID already exists in the database\n",
    "    mycursor = mydb.cursor()\n",
    "    sql_select_query = \"SELECT * FROM chat_history WHERE uuid = %s AND vec_class = %s\"\n",
    "    mycursor.execute(sql_select_query, (uuid, vec_class))\n",
    "    result = mycursor.fetchone()\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "    if result: # UUID already exists, update the existing row\n",
    "        sql_update_query = \"UPDATE chat_history SET prev_queries = CONCAT(prev_queries, CONCAT('###', %s)), chat_history = CONCAT(chat_history, CONCAT('###', %s)), logged_at = NOW() WHERE uuid = %s AND vec_class = %s\"\n",
    "        mycursor.execute(sql_update_query, (question, chat_conv, uuid, vec_class))\n",
    "        mydb.commit()\n",
    "    else: # UUID does not exist, insert a new row\n",
    "        sql_insert_query = \"INSERT INTO chat_history (vec_class, uuid, prev_queries, chat_history, logged_at) VALUES (%s, %s, %s, %s, %s)\"\n",
    "        mycursor.execute(sql_insert_query, (vec_class, uuid, question, chat_conv, timestamp))\n",
    "        mydb.commit()\n",
    "    \n",
    "\n",
    "# Define function for retrieving the last conversation for a given vec_class\n",
    "def get_last_conversation(mydb, uuid, vec_class):\n",
    "    \n",
    "    mycursor = mydb.cursor()\n",
    "    sql = \"SELECT chat_history FROM chat_history WHERE uuid = %s AND vec_class = %s\"\n",
    "    val = (uuid, vec_class)\n",
    "    mycursor.execute(sql, val)\n",
    "    result = mycursor.fetchone() #result[0] stores the last conversations ; if result is not none: return result[0]; similar in get_prev_queries\n",
    "    \n",
    "    \n",
    "    if result is not None:\n",
    "        conversations = result[0].split(\"###\")\n",
    "        context = \"###\".join(conversations[-5:])  # Keep only the most recent 3 conversations\n",
    "        prev_responses = \"###\".join([context] + conversations[:-3]) \n",
    "        return context\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Define function for retrieving the last conversation for a given vec_class\n",
    "def get_prev_queries(mydb, uuid, vec_class):\n",
    "    \n",
    "    mycursor = mydb.cursor()\n",
    "    sql = \"SELECT prev_queries FROM chat_history WHERE uuid = %s AND vec_class = %s\"\n",
    "    val = (uuid, vec_class)\n",
    "    mycursor.execute(sql, val)\n",
    "    result = mycursor.fetchone()\n",
    "     \n",
    "    \n",
    "    if result is not None:\n",
    "        conversations = result[0].split(\"###\")\n",
    "        context = \"###\".join(conversations[-5:])  # Keep only the most recent 3 conversations\n",
    "        prev_queries = \"###\".join([context] + conversations[:-3])  \n",
    "        return context\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context(question, last_conversation, vec_class):\n",
    "    \"\"\"\n",
    "    Find most relevant context for a question via Pinecone search\n",
    "    \"\"\"\n",
    "    if vec_class.upper() == 'QUESTION':\n",
    "        vec_class = 'Question'\n",
    "    elif vec_class.upper() == 'PERSONAL':\n",
    "        vec_class = 'Personal'\n",
    "    elif vec_class.upper() == 'DOCUMENTS':\n",
    "        vec_class = 'Documents'\n",
    "        \n",
    "    if last_conversation == None:\n",
    "        last_conversation = \"\"    \n",
    "    result = (\n",
    "        client.query\n",
    "        .get(vec_class, [\"question\", \"answer\"])\n",
    "        .with_hybrid(question+last_conversation, alpha=0.5)\n",
    "        .with_limit(10)\n",
    "        .do()\n",
    "    )['data']['Get'][vec_class]\n",
    "    results = []\n",
    "    for res in result:\n",
    "        results.append(res['answer'])\n",
    "    reranked_results = co.rerank(query=question, documents=results, top_n=3, model=\"rerank-multilingual-v2.0\")\n",
    "    print(\"Reranked Results: \", reranked_results)\n",
    "    \n",
    "    paragraph = ''\n",
    "    for q in result:\n",
    "        paragraph += q['question'] + ' ' + q['answer']\n",
    "    # concatenated_answers = ' '.join(answers)\n",
    "    # return concatenated_answers\n",
    "    return paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(\n",
    "    prompt,\n",
    "    debug=False,\n",
    "    max_tokens=100,\n",
    "    stop_sequence=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Answer a question based on the most similar context from the dataframe texts\n",
    "    \"\"\"\n",
    "    try:\n",
    "        #print(instruction.format(context, question))\n",
    "        response = openai.Completion.create(\n",
    "            model = \"text-davinci-003\",\n",
    "            prompt=prompt,\n",
    "            temperature=0.5,\n",
    "            max_tokens=max_tokens,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=None,\n",
    "            stream=True,\n",
    "            best_of = \n",
    "        )\n",
    "\n",
    "        generated_text = \"\"\n",
    "        for line in response:\n",
    "            generated_text += line.choices[0].text  # extract the text from the StreamingText object\n",
    "        \n",
    "        return generated_text.split(\"###\")[0].strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_tokens(prompt):\n",
    "    encoding = tiktoken.encoding_for_model(\"text-davinci-003\")\n",
    "    num_tokens = len(encoding.encode(prompt))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(uuid, vec_class, question, debug=False):\n",
    "    # Initialize Database\n",
    "    mydb = mysql.connector.connect(\n",
    "        host=\"<<Database endpoint>>\",\n",
    "        user=\"\",\n",
    "        password=\"\",\n",
    "        database=\"\"\n",
    "    )\n",
    "\n",
    "    # Retrieve last conversation for the vec_class\n",
    "    last_conversation = get_last_conversation(mydb, uuid, vec_class)\n",
    "    prev_queries = get_prev_queries(mydb, uuid, vec_class)\n",
    "\n",
    "    # Get Context for answering question\n",
    "    context = create_context(\n",
    "        question,\n",
    "        prev_queries,\n",
    "        vec_class  \n",
    "    )\n",
    "\n",
    "    # Print context while debugging\n",
    "\n",
    "        \n",
    "    \n",
    "    # If there was a previous conversation, include it in the prompt\n",
    "    if last_conversation is not None:\n",
    "        prompt = f'''You are a search and answer bot. Use the context and the Previous Responses to return only the answer relevant to the {question}. Do not repeat Previous Responses.\n",
    "            If relevant link is available in the context make sure to include them in the answer.\n",
    "            and if the question can't be answered based on the context,\n",
    "            say \\\"Sorry! I have no information available for that at the moment\\\"\\n\\n Context: \\n{context}\\n\\n---\\n\\n Previous Responses: {last_conversation}\\n Question: {question}\\n Answer:\n",
    "        '''\n",
    "    else:\n",
    "        prompt = f'''You are a search and answer bot. Use the context to return only the answer relevant to the {question}.\n",
    "            If relevant link is available in the context include them in the answer.\n",
    "            and if the question can't be answered based on the context,\n",
    "            say \\\"Sorry! I have no information available for that at the moment\\\"\\n\\n Context: \\n{context}\\n\\n---\\n\\n Question: {question}\\n Answer:\n",
    "        '''\n",
    "    \n",
    "    num_tokens = calculate_tokens(prompt)\n",
    "\n",
    "    if debug:\n",
    "        print(\"Last 3 Queries: \", prev_queries)\n",
    "        print(\"Last 3 Conversation: \", last_conversation)\n",
    "        print(context)\n",
    "        print(\"Num Tokens: \", num_tokens)\n",
    "    \n",
    "    # Generate response from OpenAI API\n",
    "    response = generate_response(prompt)\n",
    "    \n",
    "    # Insert conversation into the database\n",
    "    # uuid = str(uuid.uuid4())\n",
    "    # chat_conv = f\"{context}\\n\\n---\\n\\nQuestion: {question}\\nAnswer: {response}\"\n",
    "    chat_conv = f\"Question: {question} Answer: {response}\"\n",
    "    insert_data(mydb, vec_class, uuid, question, chat_conv)\n",
    "\n",
    "    mydb.close()\n",
    "    \n",
    "    # Return response to the user\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =''\n",
    "uuid=''\n",
    "vec_class = ''\n",
    "lang_code = detect_lang(query)\n",
    "print(lang_code)\n",
    "if lang_code == 'EN':\n",
    "    result = chatbot(uuid, vec_class, query, debug = True)\n",
    "else:\n",
    "    trans_query = user_lang(query, 'EN')\n",
    "    answer = chatbot(uuid, vec_class, trans_query, debug = True)\n",
    "    result = user_lang(answer, lang_code)\n",
    "\n",
    "print(result)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intentrec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
